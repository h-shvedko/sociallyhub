import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { authOptions } from '@/lib/auth'
import prisma from '@/lib/prisma'
import { normalizeUserId } from '@/lib/auth-utils'

export async function GET(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions)
    if (!session?.user?.id) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const userId = normalizeUserId(session.user.id)
    const userWorkspace = await prisma.userWorkspace.findFirst({
      where: { userId },
      select: { workspaceId: true }
    })

    if (!userWorkspace) {
      return NextResponse.json({ error: 'No workspace found' }, { status: 403 })
    }

    const { searchParams } = new URL(request.url)
    const videoId = searchParams.get('videoId')

    if (videoId) {
      // Get transcript for specific video
      const video = await prisma.videoTutorial.findFirst({
        where: {
          id: videoId,
          workspaceId: userWorkspace.workspaceId
        },
        select: {
          id: true,
          title: true,
          transcript: true,
          transcriptLanguage: true,
          hasAutoTranscript: true
        }
      })

      if (!video) {
        return NextResponse.json({ error: 'Video not found' }, { status: 404 })
      }

      return NextResponse.json({
        videoId: video.id,
        videoTitle: video.title,
        transcript: video.transcript,
        language: video.transcriptLanguage,
        isAutoGenerated: video.hasAutoTranscript,
        hasTranscript: !!video.transcript
      })
    }

    // Get all videos with transcript status
    const videos = await prisma.videoTutorial.findMany({
      where: {
        workspaceId: userWorkspace.workspaceId
      },
      select: {
        id: true,
        title: true,
        duration: true,
        status: true,
        transcript: true,
        transcriptLanguage: true,
        hasAutoTranscript: true,
        createdAt: true
      },
      orderBy: { createdAt: 'desc' }
    })

    const transcriptStats = videos.reduce((stats, video) => {
      stats.total += 1
      if (video.transcript) {
        stats.withTranscripts += 1
        if (video.hasAutoTranscript) {
          stats.autoGenerated += 1
        } else {
          stats.manual += 1
        }
      } else {
        stats.withoutTranscripts += 1
      }
      return stats
    }, {
      total: 0,
      withTranscripts: 0,
      withoutTranscripts: 0,
      autoGenerated: 0,
      manual: 0
    })

    return NextResponse.json({
      videos: videos.map(video => ({
        ...video,
        hasTranscript: !!video.transcript,
        transcriptLength: video.transcript ? video.transcript.length : 0
      })),
      stats: transcriptStats
    })
  } catch (error) {
    console.error('Error fetching transcripts:', error)
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}

export async function POST(request: NextRequest) {
  try {
    const session = await getServerSession(authOptions)
    if (!session?.user?.id) {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const userId = normalizeUserId(session.user.id)
    const userWorkspace = await prisma.userWorkspace.findFirst({
      where: { userId },
      select: { workspaceId: true }
    })

    if (!userWorkspace) {
      return NextResponse.json({ error: 'No workspace found' }, { status: 403 })
    }

    const body = await request.json()
    const {
      videoId,
      transcript,
      language = 'en',
      action = 'upload',
      format = 'text'
    } = body

    // Verify video belongs to workspace
    const video = await prisma.videoTutorial.findFirst({
      where: {
        id: videoId,
        workspaceId: userWorkspace.workspaceId
      }
    })

    if (!video) {
      return NextResponse.json({ error: 'Video not found' }, { status: 404 })
    }

    if (action === 'upload') {
      // Manual transcript upload
      if (!transcript) {
        return NextResponse.json({
          error: 'Transcript content is required'
        }, { status: 400 })
      }

      // Process transcript based on format
      let processedTranscript = transcript

      if (format === 'srt') {
        // Convert SRT format to plain text with timestamps
        processedTranscript = parseSRTToText(transcript)
      } else if (format === 'vtt') {
        // Convert WebVTT format to plain text with timestamps
        processedTranscript = parseVTTToText(transcript)
      }

      const updatedVideo = await prisma.videoTutorial.update({
        where: { id: videoId },
        data: {
          transcript: processedTranscript,
          transcriptLanguage: language,
          hasAutoTranscript: false,
          updatedAt: new Date()
        }
      })

      return NextResponse.json({
        success: true,
        message: 'Transcript uploaded successfully',
        videoId: updatedVideo.id,
        transcriptLength: processedTranscript.length,
        language
      })
    }

    if (action === 'auto_generate') {
      // Auto-generate transcript (mock implementation)
      // In production, this would integrate with services like:
      // - Google Cloud Speech-to-Text
      // - Amazon Transcribe
      // - Azure Speech Service
      // - OpenAI Whisper

      const mockTranscript = generateMockTranscript(video.title, video.duration || 300)

      const updatedVideo = await prisma.videoTutorial.update({
        where: { id: videoId },
        data: {
          transcript: mockTranscript,
          transcriptLanguage: language,
          hasAutoTranscript: true,
          updatedAt: new Date()
        }
      })

      return NextResponse.json({
        success: true,
        message: 'Transcript auto-generated successfully',
        videoId: updatedVideo.id,
        transcript: mockTranscript,
        language,
        isAutoGenerated: true
      })
    }

    if (action === 'delete') {
      await prisma.videoTutorial.update({
        where: { id: videoId },
        data: {
          transcript: null,
          transcriptLanguage: null,
          hasAutoTranscript: false,
          updatedAt: new Date()
        }
      })

      return NextResponse.json({
        success: true,
        message: 'Transcript deleted successfully'
      })
    }

    return NextResponse.json({
      error: 'Invalid action. Supported: upload, auto_generate, delete'
    }, { status: 400 })
  } catch (error) {
    console.error('Error processing transcript:', error)
    return NextResponse.json({ error: 'Internal server error' }, { status: 500 })
  }
}

// Helper function to parse SRT format
function parseSRTToText(srtContent: string): string {
  const lines = srtContent.split('\n')
  const textLines = []

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim()
    // Skip sequence numbers and timestamps
    if (line && !line.match(/^\d+$/) && !line.match(/\d{2}:\d{2}:\d{2}/)) {
      textLines.push(line)
    }
  }

  return textLines.join(' ')
}

// Helper function to parse WebVTT format
function parseVTTToText(vttContent: string): string {
  const lines = vttContent.split('\n')
  const textLines = []

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i].trim()
    // Skip WebVTT header, timestamps, and styling
    if (line &&
        !line.startsWith('WEBVTT') &&
        !line.match(/\d{2}:\d{2}:\d{2}/) &&
        !line.startsWith('<')) {
      textLines.push(line)
    }
  }

  return textLines.join(' ')
}

// Helper function to generate mock transcript
function generateMockTranscript(title: string, duration: number): string {
  const introductions = [
    `Welcome to this tutorial on ${title}.`,
    `In this video, we'll be covering ${title}.`,
    `Hello everyone, today we're going to learn about ${title}.`,
    `Let's get started with ${title}.`
  ]

  const conclusions = [
    'Thank you for watching this tutorial.',
    'That concludes our lesson for today.',
    'I hope you found this tutorial helpful.',
    'Thanks for following along!'
  ]

  const segments = [
    'First, let\'s understand the basic concepts.',
    'Now, let\'s dive into the practical examples.',
    'Here are some important points to remember.',
    'Let\'s take a look at a real-world scenario.',
    'This is a common pattern you\'ll encounter.',
    'Pay attention to this particular detail.',
    'Let me walk you through this step by step.',
    'This technique is very useful in practice.'
  ]

  const intro = introductions[Math.floor(Math.random() * introductions.length)]
  const conclusion = conclusions[Math.floor(Math.random() * conclusions.length)]

  // Generate segments based on duration (roughly 1 segment per 30 seconds)
  const numSegments = Math.max(1, Math.floor(duration / 30))
  const selectedSegments = []

  for (let i = 0; i < numSegments; i++) {
    selectedSegments.push(segments[Math.floor(Math.random() * segments.length)])
  }

  return [intro, ...selectedSegments, conclusion].join(' ')
}